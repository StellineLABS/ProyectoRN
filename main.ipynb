{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d5e849-5155-426f-b8ba-f38c9f1f15fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dataloader\n",
    "import model\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d9b27a-25c1-4c15-8c23-549a0af1f644",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Funciones auxiliares para el dataset\n",
    "def crear_csv():\n",
    "    df = pd.read_csv('samples.csv')\n",
    "    # Vector con todos los posibles identificadores \n",
    "    labels = []\n",
    "    for n in range(10):\n",
    "        labels.append('T00' + str(n))\n",
    "    for n in range(10,100):\n",
    "        labels.append('T0' + str(n))\n",
    "    for n in range(100,201):\n",
    "        labels.append('T' + str(n))\n",
    "    label = np.array(labels)\n",
    "    np.random.shuffle(label)\n",
    "    numeros = np\n",
    "    nd=201\n",
    "    # Creamos el csv que guarde todos los posibles identificadores \n",
    "    d = {'index': list(range(0,nd )), 'mid': label, 'display_name':[\"''\"]*nd}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    df.to_csv('class_labels_indices.csv', index = False)\n",
    "\n",
    "def crear_json():\n",
    "    directory = 'canciones'\n",
    "    df = pd.read_csv('samples.csv')\n",
    "    diccionarios = []\n",
    "    # Iteramos sobre archivos en ./canciones\n",
    "    for filename in os.listdir(directory):\n",
    "        direccion = os.path.join(directory, filename)\n",
    "        if os.path.isfile(direccion):\n",
    "            # Quitamos extensión\n",
    "            original = filename.replace(\".flac\", \"\")\n",
    "            # Determinamos qué samples contiene cada canción según samples.csv\n",
    "            etiquetas = [*set([str(df['original_track_id'][i]) for i in list(df.index[df['sample_track_id'] == original])])]\n",
    "            if len(etiquetas) != 0:\n",
    "                etiquetas = etiquetas[0]\n",
    "            else:\n",
    "                # Placeholder si una canción no contiene samples\n",
    "                etiquetas = 'T000'\n",
    "            diccionario = {\n",
    "            \"wav\": direccion,\n",
    "            \"labels\": etiquetas\n",
    "            }\n",
    "            diccionarios.append(diccionario)\n",
    "            \n",
    "    data = {\n",
    "        \"data\":diccionarios\n",
    "    }\n",
    "    json_object = json.dumps(data, indent=4)\n",
    "    # Creamos json del dataset\n",
    "    with open(\"train_data.json\", \"w\") as outfile:\n",
    "        outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c620d88-d5b1-432b-9b49-65b031f26571",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creamos archivos auxiliares\n",
    "crear_csv()\n",
    "crear_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b34521",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Entrenamiento\n",
    "def train(model, epochs,data_loader,criterion,optimizer,cuda=False):\n",
    "        x = np.arange(1, epochs + 1)\n",
    "        y = np.empty(epochs)\n",
    "        start = time.time()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "            for i, (inputs, labels) in enumerate(train_loader):\n",
    "                if (cuda == True):\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                with autocast():\n",
    "                    outputs = model.forward(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "            y[epoch] = running_loss\n",
    "            \n",
    "        end = time.time()\n",
    "        print(\"El entrenamiento tomó \" + str(end - start) + \" segundos.\")\n",
    "        # Grafica loss\n",
    "        plt.plot(x, y)\n",
    "        plt.xlabel('Número de epochs')\n",
    "        plt.ylabel('Error')\n",
    "        plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9766c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cargamos datos de entrenamiento\n",
    "labels = 'class_labels_indices.csv'\n",
    "data = dataloader.AudiosetDataset('train_data.json', label_csv = labels)\n",
    "train_loader = torch.utils.data.DataLoader(data,batch_size=8,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a083a64-3077-4551-bc57-594b6391749d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creamos y entrenamos modelo\n",
    "modelo_audio = model.ASTModel(class_n = 201)\n",
    "modelo_audio = modelo_audio.to(device)\n",
    "entrenables = [p for p in modelo_audio.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(entrenables, 0.001, weight_decay=5e-7, betas=(0.95, 0.999))\n",
    "criterio = torch.nn.CrossEntropyLoss()\n",
    "#Entrenamos la red durante 50 pasos, con entropia cruzada y el optimizador ADAM\n",
    "train(modelo_audio, 2,train_loader,criterio,optimizer,cuda=True)\n",
    "# Guardar modelo\n",
    "PATH = './modelo_audio.pth'\n",
    "torch.save(modelo_audio.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df23b3f9-7cb4-4930-b6a9-3bfc1e58596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recomiendo ejecutar esto en lugar del entrenamiento\n",
    "PATH = './modelo_audio.pth'\n",
    "modelo_audio = model.ASTModel(class_n = 201)\n",
    "modelo_audio.load_state_dict(torch.load(PATH))\n",
    "modelo_audio = modelo_audio.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea082b33-fad8-40a2-b297-dd2f84fcac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones para evaluación\n",
    "def contarCorrectas(net,batch,labels,func=None):\n",
    "    '''Dado un batch y sus etiquetas, cuenta el numero de respuestas\n",
    "    correctas de una red, el parametro func aplica una modificacion al \n",
    "    tensor que contiene los datos'''\n",
    "    salidas=net(batch)\n",
    "    cantidadCorrectas = 0\n",
    "    for (output, label) in zip(salidas, labels):\n",
    "        if torch.argmax(output) == torch.argmax(label):\n",
    "            cantidadCorrectas = cantidadCorrectas + 1\n",
    "    return cantidadCorrectas\n",
    "    \n",
    "def calcularPrecisionGlobal(net,data_loader,batch_size,cuda=False):\n",
    "    '''Calcula la precision de una red dado un data_loader,\n",
    "    recive una funcion que transforma los datos en caso de ser necesario'''\n",
    "    correctas=0\n",
    "    for (images,labels) in data_loader:\n",
    "        if(cuda and torch.cuda.is_available()):\n",
    "            images=images.cuda()\n",
    "            labels=labels.cuda()\n",
    "        correctas+=contarCorrectas(net,images,labels)\n",
    "    return (100*correctas)/(len(data_loader)*batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bd45d9-8bac-4577-ace4-e633f92b87a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "precision = calcularPrecisionGlobal(modelo_audio,train_loader,8, cuda = True)\n",
    "print(\"Precision del modelo: %.4f%%\"%(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333d9b60-25b4-419c-8bd0-fc7e67da01e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
